"""
Video Statistics Analyzer
==========================

JSON ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ë¹„ë””ì˜¤ ê¸¸ì´ í†µê³„ë¥¼ ë¶„ì„í•˜ê³  ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.

ì‚¬ìš©ë²• (Usage)
-------------

1. ê¸°ë³¸ ì‚¬ìš© (ëª¨ë“  í´ë” ë¶„ì„)
   $ python video_stats_analyzer.py

2. ë‚ ì§œ ë²”ìœ„ë¡œ ë¶„ì„
   $ python video_stats_analyzer.py --start-date 20250901 --end-date 20250930
   $ python video_stats_analyzer.py --start-date 20250901  # ì‹œì‘ì¼ ì´í›„ ì „ë¶€
   $ python video_stats_analyzer.py --end-date 20250930    # ì¢…ë£Œì¼ ì´ì „ ì „ë¶€

3. í´ë” ëª©ë¡ í™•ì¸ (ë¶„ì„ ì—†ì´ ëª©ë¡ë§Œ ì¶œë ¥)
   $ python video_stats_analyzer.py --list
   $ python video_stats_analyzer.py --list --start-date 20250901

4. ì´ë¯¸ ì²˜ë¦¬ëœ í´ë” ì¬ë¶„ì„
   $ python video_stats_analyzer.py --reprocess
   $ python video_stats_analyzer.py --reprocess --start-date 20250901

5. ì»¤ìŠ¤í…€ ê²½ë¡œ ì§€ì •
   $ python video_stats_analyzer.py --base-path ./my_videos --output-dir ./my_stats

ì˜µì…˜ (Options)
--------------
  --base-path PATH      ì—…ë¡œë“œ í´ë”ê°€ ìˆëŠ” ê¸°ë³¸ ê²½ë¡œ (ê¸°ë³¸ê°’: data/uploads)
  --output-dir PATH     í†µê³„ ê²°ê³¼ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: stats_output)
  --start-date DATE     ì‹œì‘ ë‚ ì§œ (YYYYMMDD í˜•ì‹, ì˜ˆ: 20250901)
  --end-date DATE       ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD í˜•ì‹, ì˜ˆ: 20250930)
  --list                í´ë” ëª©ë¡ë§Œ ì¶œë ¥ (ë¶„ì„ ì•ˆí•¨)
  --reprocess           ì´ë¯¸ ì²˜ë¦¬ëœ í´ë”ë„ ë‹¤ì‹œ ì²˜ë¦¬
  -h, --help            ë„ì›€ë§ ì¶œë ¥

ë””ë ‰í† ë¦¬ êµ¬ì¡° (Directory Structure)
-----------------------------------
project/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ uploads/
â”‚       â”œâ”€â”€ upload_20250829_001/
â”‚       â”‚   â””â”€â”€ manifests/
â”‚       â”‚       â”œâ”€â”€ video1.json
â”‚       â”‚       â””â”€â”€ video2.json
â”‚       â”œâ”€â”€ upload_20250901_002/
â”‚       â””â”€â”€ upload_20250915_003/
â”œâ”€â”€ stats_output/          # ìë™ ìƒì„±ë¨
â”‚   â”œâ”€â”€ processed_folders.json
â”‚   â”œâ”€â”€ video_stats_upload_20250829_001.csv
â”‚   â”œâ”€â”€ video_durations_raw_upload_20250829_001.csv
â”‚   â””â”€â”€ invalid_files_upload_20250829_001.csv
â””â”€â”€ video_stats_analyzer.py

JSON í˜•ì‹ ìš”êµ¬ì‚¬í•­
------------------
ë§¤ë‹ˆí˜ìŠ¤íŠ¸ JSON íŒŒì¼ì€ ë‹¤ìŒ í˜•ì‹ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
{
  "duration": "HH:MM:SS",
  ...
}

ì¶œë ¥ íŒŒì¼ (Output Files)
------------------------
1. video_stats_*.csv           - í´ë”ë³„ í†µê³„ ìš”ì•½
2. video_durations_raw_*.csv   - ê°œë³„ ë¹„ë””ì˜¤ ê¸¸ì´ ì›ë³¸ ë°ì´í„°
3. invalid_files_*.csv         - ì²˜ë¦¬ ì‹¤íŒ¨í•œ íŒŒì¼ ëª©ë¡
4. processed_folders.json      - ì²˜ë¦¬ ì™„ë£Œëœ í´ë” ì¶”ì  ë¡œê·¸

"""

import os
import json
import statistics
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path
import re
from typing import List, Optional, Tuple


class VideoStatsAnalyzer:
    """
    ë¹„ë””ì˜¤ í†µê³„ ë¶„ì„ê¸°
    - ë¡œì»¬ í´ë”ì—ì„œ JSON ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ì„ ì½ì–´ ì˜ìƒ ê¸¸ì´ í†µê³„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
    - ë‚ ì§œ ë²”ìœ„ë¥¼ ì§€ì •í•˜ì—¬ íŠ¹ì • ê¸°ê°„ì˜ ë°ì´í„°ë§Œ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
    """
    
    def __init__(self, base_path: str = "data/uploads", output_dir: str = "stats_output"):
        """
        Args:
            base_path: ì—…ë¡œë“œ í´ë”ë“¤ì´ ìˆëŠ” ê¸°ë³¸ ê²½ë¡œ
            output_dir: í†µê³„ ê²°ê³¼ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬
        """
        self.base_path = Path(base_path)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True, parents=True)
        self.processed_log_file = self.output_dir / "processed_folders.json"
        self.processed_folders = self.load_processed_folders()
    
    def load_processed_folders(self) -> set:
        """ì²˜ë¦¬ëœ í´ë” ëª©ë¡ì„ ë¡œë“œ"""
        if self.processed_log_file.exists():
            with open(self.processed_log_file, 'r', encoding='utf-8') as f:
                return set(json.load(f))
        return set()
    
    def save_processed_folders(self):
        """ì²˜ë¦¬ëœ í´ë” ëª©ë¡ì„ ì €ì¥"""
        with open(self.processed_log_file, 'w', encoding='utf-8') as f:
            json.dump(sorted(list(self.processed_folders)), f, indent=2, ensure_ascii=False)
    
    def extract_date_from_folder(self, folder_name: str) -> Optional[str]:
        """
        í´ë”ëª…ì—ì„œ ë‚ ì§œë¥¼ ì¶”ì¶œ
        ì˜ˆ: 'upload_20250829_001' -> '20250829'
        
        Args:
            folder_name: í´ë”ëª…
            
        Returns:
            YYYYMMDD í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´ ë˜ëŠ” None
        """
        match = re.search(r'(\d{8})', folder_name)
        if match:
            return match.group(1)
        return None
    
    def is_folder_in_date_range(
        self, 
        folder_name: str, 
        start_date: Optional[str] = None, 
        end_date: Optional[str] = None
    ) -> bool:
        """
        í´ë”ê°€ ì§€ì •ëœ ë‚ ì§œ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
        
        Args:
            folder_name: í´ë”ëª…
            start_date: ì‹œì‘ ë‚ ì§œ (YYYYMMDD í˜•ì‹), Noneì´ë©´ ì œí•œ ì—†ìŒ
            end_date: ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD í˜•ì‹), Noneì´ë©´ ì œí•œ ì—†ìŒ
            
        Returns:
            ë‚ ì§œ ë²”ìœ„ ë‚´ì— ìˆìœ¼ë©´ True
        """
        folder_date = self.extract_date_from_folder(folder_name)
        
        if folder_date is None:
            print(f"âš ï¸ í´ë”ëª…ì—ì„œ ë‚ ì§œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŒ: {folder_name}")
            return False
        
        if start_date and folder_date < start_date:
            return False
        
        if end_date and folder_date > end_date:
            return False
        
        return True
    
    def get_upload_folders(
        self, 
        start_date: Optional[str] = None, 
        end_date: Optional[str] = None
    ) -> List[Path]:
        """
        ì—…ë¡œë“œ í´ë” ëª©ë¡ì„ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            start_date: ì‹œì‘ ë‚ ì§œ (YYYYMMDD)
            end_date: ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD)
            
        Returns:
            í•„í„°ë§ëœ í´ë” ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        if not self.base_path.exists():
            print(f"âŒ ê¸°ë³¸ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.base_path}")
            return []
        
        all_folders = [f for f in self.base_path.iterdir() if f.is_dir()]
        
        # ë‚ ì§œ ë²”ìœ„ í•„í„°ë§
        filtered_folders = [
            folder for folder in all_folders
            if self.is_folder_in_date_range(folder.name, start_date, end_date)
        ]
        
        if start_date or end_date:
            date_info = f"{start_date or 'ì‹œì‘'} ~ {end_date or 'ì¢…ë£Œ'}"
            print(f"ğŸ“… ì „ì²´ í´ë”: {len(all_folders)}ê°œ â†’ í•„í„°ë§ í›„: {len(filtered_folders)}ê°œ ({date_info})")
        else:
            print(f"ğŸ“‚ ì „ì²´ í´ë”: {len(all_folders)}ê°œ")
        
        return sorted(filtered_folders)
    
    def parse_duration(self, duration_str: str) -> int:
        """
        duration ë¬¸ìì—´ì„ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜
        
        Args:
            duration_str: "HH:MM:SS" í˜•ì‹ì˜ ë¬¸ìì—´
            
        Returns:
            ì´ˆ ë‹¨ìœ„ ì‹œê°„
        """
        try:
            t = datetime.strptime(duration_str, "%H:%M:%S")
            delta = timedelta(hours=t.hour, minutes=t.minute, seconds=t.second)
            return int(delta.total_seconds())
        except Exception as e:
            print(f"âš ï¸ ì˜ëª»ëœ duration í˜•ì‹: {duration_str} - {e}")
            return 0
    
    def seconds_to_hms(self, seconds: int) -> str:
        """
        ì´ˆë¥¼ ì‹œ:ë¶„:ì´ˆ í˜•íƒœë¡œ ë³€í™˜
        
        Args:
            seconds: ì´ˆ ë‹¨ìœ„ ì‹œê°„
            
        Returns:
            "H:MM:SS" í˜•ì‹ì˜ ë¬¸ìì—´
        """
        hours, remainder = divmod(int(seconds), 3600)
        minutes, secs = divmod(remainder, 60)
        return f"{hours}:{minutes:02d}:{secs:02d}"
    
    def get_json_files_from_folder(self, folder_path: Path) -> List[Path]:
        """
        íŠ¹ì • í´ë”ì˜ manifests ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  JSON íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            folder_path: í´ë” ê²½ë¡œ
            
        Returns:
            JSON íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        manifests_dir = folder_path / "manifests"
        
        if not manifests_dir.exists():
            return []
        
        return list(manifests_dir.glob("*.json"))
    
    def process_folder(self, folder_path: Path) -> bool:
        """
        íŠ¹ì • í´ë”ì˜ ì˜ìƒ ê¸¸ì´ í†µê³„ë¥¼ ì²˜ë¦¬
        
        Args:
            folder_path: ì²˜ë¦¬í•  í´ë” ê²½ë¡œ
            
        Returns:
            ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
        """
        folder_name = folder_path.name
        folder_date = self.extract_date_from_folder(folder_name)
        
        print(f"\n{'='*60}")
        print(f"í´ë” ì²˜ë¦¬ ì‹œì‘: {folder_name} ({folder_date})")
        print(f"{'='*60}")
        
        # JSON íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        json_files = self.get_json_files_from_folder(folder_path)
        print(f"JSON íŒŒì¼ ë°œê²¬: {len(json_files)}ê°œ")
        
        if not json_files:
            print(f"âš ï¸ í´ë” {folder_name}ì—ì„œ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # ì˜ìƒ ê¸¸ì´ ë° ìœ íš¨í•˜ì§€ ì•Šì€ íŒŒì¼ ì¶”ì 
        durations_seconds = []
        invalid_files = []
        
        print(f"JSON íŒŒì¼ ì½ëŠ” ì¤‘... (ì´ {len(json_files)}ê°œ íŒŒì¼)")
        
        for i, json_file in enumerate(json_files, 1):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                duration_str = data.get('duration', None)
                if duration_str:
                    duration_seconds = self.parse_duration(duration_str)
                    if duration_seconds > 0:
                        durations_seconds.append(duration_seconds)
                    else:
                        invalid_files.append({
                            'file': json_file.name,
                            'reason': 'parse_duration returned 0',
                            'duration_str': duration_str
                        })
                else:
                    invalid_files.append({
                        'file': json_file.name,
                        'reason': 'no duration field',
                        'data_keys': ', '.join(data.keys())
                    })
                
                # ì§„í–‰ìƒí™© í‘œì‹œ
                if i % 100 == 0 or i == len(json_files):
                    print(f"ì§„í–‰ì¤‘... {i}/{len(json_files)} íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")
                    
            except Exception as e:
                print(f"âš ï¸ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({json_file.name}): {e}")
                invalid_files.append({
                    'file': json_file.name,
                    'reason': f'Exception: {str(e)}'
                })
        
        # ìœ íš¨í•˜ì§€ ì•Šì€ íŒŒì¼ ë¡œê·¸
        if invalid_files:
            print(f"\nâš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ íŒŒì¼: {len(invalid_files)}ê°œ")
            for invalid in invalid_files[:10]:
                print(f"  - {invalid['file']}: {invalid['reason']}")
            if len(invalid_files) > 10:
                print(f"  ... ì™¸ {len(invalid_files) - 10}ê°œ")
            
            # ìœ íš¨í•˜ì§€ ì•Šì€ íŒŒì¼ ëª©ë¡ ì €ì¥
            invalid_csv_path = self.output_dir / f"invalid_files_{folder_name}.csv"
            invalid_df = pd.DataFrame(invalid_files)
            invalid_df.to_csv(invalid_csv_path, index=False, encoding='utf-8-sig')
            print(f"  â†’ ìƒì„¸ ì •ë³´ ì €ì¥: {invalid_csv_path}")
        
        if not durations_seconds:
            print(f"âš ï¸ í´ë” {folder_name}ì—ì„œ ìœ íš¨í•œ ì˜ìƒ ê¸¸ì´ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # í†µê³„ ê³„ì‚°
        total_videos = len(durations_seconds)
        total_duration_seconds = sum(durations_seconds)
        average_duration_seconds = total_duration_seconds / total_videos
        min_duration_seconds = min(durations_seconds)
        max_duration_seconds = max(durations_seconds)
        median_duration_seconds = statistics.median(durations_seconds)
        
        # ê¸¸ì´ë³„ ë¶„í¬ ê³„ì‚°
        ranges = [
            (0, 60), (60, 300), (300, 600), (600, 1800),
            (1800, 2400), (2400, 3000), (3000, 3600), (3600, float('inf'))
        ]
        range_labels = [
            "1ë¶„ ë¯¸ë§Œ", "5ë¶„ ë¯¸ë§Œ", "10ë¶„ ë¯¸ë§Œ", "30ë¶„ ë¯¸ë§Œ",
            "40ë¶„ ë¯¸ë§Œ", "50ë¶„ ë¯¸ë§Œ", "60ë¶„ ë¯¸ë§Œ", "1ì‹œê°„ ì´ìƒ"
        ]
        
        distribution = {}
        for (min_sec, max_sec), label in zip(ranges, range_labels):
            count = len([d for d in durations_seconds if min_sec <= d < max_sec])
            percentage = (count / total_videos) * 100
            distribution[f"{label}_ê°œìˆ˜"] = count
            distribution[f"{label}_ë¹„ìœ¨"] = round(percentage, 1)
        
        # í†µê³„ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥
        stats_data = {
            "í´ë”ëª…": [folder_name],
            "í´ë”ë‚ ì§œ": [folder_date],
            "ì²˜ë¦¬ì‹œê°„": [datetime.now().strftime('%Y-%m-%d %H:%M:%S')],
            "ë°œê²¬ëœ_JSON_íŒŒì¼": [len(json_files)],
            "ìœ íš¨í•œ_íŒŒì¼": [total_videos],
            "ë¬´íš¨í•œ_íŒŒì¼": [len(invalid_files)],
            "ì´_ì˜ìƒ_ê°œìˆ˜": [total_videos],
            "ì´_ì˜ìƒ_ì‹œê°„_ì´ˆ": [total_duration_seconds],
            "ì´_ì˜ìƒ_ì‹œê°„_HMS": [self.seconds_to_hms(total_duration_seconds)],
            "í‰ê· _ê¸¸ì´_ì´ˆ": [round(average_duration_seconds, 2)],
            "í‰ê· _ê¸¸ì´_HMS": [self.seconds_to_hms(average_duration_seconds)],
            "ìµœì†Œ_ê¸¸ì´_ì´ˆ": [min_duration_seconds],
            "ìµœì†Œ_ê¸¸ì´_HMS": [self.seconds_to_hms(min_duration_seconds)],
            "ìµœëŒ€_ê¸¸ì´_ì´ˆ": [max_duration_seconds],
            "ìµœëŒ€_ê¸¸ì´_HMS": [self.seconds_to_hms(max_duration_seconds)],
            "ì¤‘ê°„ê°’_ì´ˆ": [median_duration_seconds],
            "ì¤‘ê°„ê°’_HMS": [self.seconds_to_hms(median_duration_seconds)]
        }
        
        # ë¶„í¬ ë°ì´í„° ì¶”ê°€
        stats_data.update({key: [value] for key, value in distribution.items()})
        
        # DataFrame ìƒì„± ë° CSV ì €ì¥
        stats_df = pd.DataFrame(stats_data)
        csv_path = self.output_dir / f"video_stats_{folder_name}.csv"
        stats_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        
        # ê°œë³„ ì˜ìƒ ê¸¸ì´ ë°ì´í„°ë„ ì €ì¥
        durations_df = pd.DataFrame(durations_seconds, columns=["duration_sec"])
        durations_csv_path = self.output_dir / f"video_durations_raw_{folder_name}.csv"
        durations_df.to_csv(durations_csv_path, index=False)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nâœ… ì˜ìƒ ê¸¸ì´ í†µê³„ ë¶„ì„ ê²°ê³¼ - {folder_name}")
        print("="*50)
        print(f"í´ë” ë‚ ì§œ: {folder_date}")
        print(f"ë°œê²¬ëœ JSON íŒŒì¼: {len(json_files)}ê°œ")
        print(f"ìœ íš¨í•œ íŒŒì¼: {total_videos}ê°œ")
        print(f"ë¬´íš¨í•œ íŒŒì¼: {len(invalid_files)}ê°œ")
        print(f"ì´ ì˜ìƒ ê°œìˆ˜: {total_videos}ê°œ")
        print(f"ì´ ì˜ìƒ ì‹œê°„: {self.seconds_to_hms(total_duration_seconds)}")
        print(f"í‰ê·  ê¸¸ì´: {self.seconds_to_hms(average_duration_seconds)}")
        print(f"ìµœì†Œ ê¸¸ì´: {self.seconds_to_hms(min_duration_seconds)}")
        print(f"ìµœëŒ€ ê¸¸ì´: {self.seconds_to_hms(max_duration_seconds)}")
        print(f"ì¤‘ê°„ê°’: {self.seconds_to_hms(median_duration_seconds)}")
        print("="*50)
        
        # ê¸¸ì´ë³„ ë¶„í¬ ì¶œë ¥
        print(f"\nğŸ“Š ê¸¸ì´ ë¶„í¬:")
        for (min_sec, max_sec), label in zip(ranges, range_labels):
            count = len([d for d in durations_seconds if min_sec <= d < max_sec])
            percentage = (count / total_videos) * 100
            print(f"  {label}: {count}ê°œ ({percentage:.1f}%)")
        
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:")
        print(f"  - í†µê³„ CSV: {csv_path}")
        print(f"  - ì›ë³¸ ë°ì´í„° CSV: {durations_csv_path}")
        if invalid_files:
            print(f"  - ë¬´íš¨ íŒŒì¼ ëª©ë¡: {invalid_csv_path}")
        
        return True
    
    def analyze_folders(
        self, 
        start_date: Optional[str] = None, 
        end_date: Optional[str] = None,
        skip_processed: bool = True
    ):
        """
        í´ë”ë“¤ì„ ë¶„ì„í•˜ê³  í†µê³„ë¥¼ ìƒì„±
        
        Args:
            start_date: ì‹œì‘ ë‚ ì§œ (YYYYMMDD)
            end_date: ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD)
            skip_processed: ì´ë¯¸ ì²˜ë¦¬ëœ í´ë”ë¥¼ ê±´ë„ˆë›¸ì§€ ì—¬ë¶€
        """
        folders = self.get_upload_folders(start_date, end_date)
        
        if not folders:
            print("âŒ ë¶„ì„í•  í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nğŸš€ ì´ {len(folders)}ê°œì˜ í´ë” ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        success_count = 0
        skip_count = 0
        
        for i, folder in enumerate(folders, 1):
            folder_name = folder.name
            
            if skip_processed and folder_name in self.processed_folders:
                print(f"\n[{i}/{len(folders)}] â­ï¸ ì´ë¯¸ ì²˜ë¦¬ëœ í´ë”: {folder_name}")
                skip_count += 1
                continue
            
            print(f"\n[{i}/{len(folders)}] ì²˜ë¦¬ ì¤‘: {folder_name}")
            
            if self.process_folder(folder):
                self.processed_folders.add(folder_name)
                success_count += 1
        
        self.save_processed_folders()
        
        print(f"\n{'='*60}")
        print(f"âœ… ë¶„ì„ ì™„ë£Œ!")
        print(f"  - ì„±ê³µ: {success_count}ê°œ")
        print(f"  - ê±´ë„ˆëœ€: {skip_count}ê°œ")
        print(f"  - ì „ì²´ ì²˜ë¦¬ëœ í´ë”: {len(self.processed_folders)}ê°œ")
        print(f"{'='*60}")
    
    def list_folders(
        self, 
        start_date: Optional[str] = None, 
        end_date: Optional[str] = None
    ):
        """
        í´ë” ëª©ë¡ ì¶œë ¥
        
        Args:
            start_date: ì‹œì‘ ë‚ ì§œ (YYYYMMDD)
            end_date: ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD)
        """
        folders = self.get_upload_folders(start_date, end_date)
        
        if not folders:
            print("âŒ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nğŸ“‚ í´ë” ëª©ë¡ ({len(folders)}ê°œ):")
        print("="*60)
        
        for i, folder in enumerate(folders, 1):
            folder_name = folder.name
            folder_date = self.extract_date_from_folder(folder_name)
            processed = "âœ“" if folder_name in self.processed_folders else " "
            print(f"[{processed}] {i}. {folder_name} ({folder_date})")
        
        print("="*60)
        print(f"âœ“ = ì´ë¯¸ ì²˜ë¦¬ëœ í´ë”")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="ë¹„ë””ì˜¤ í†µê³„ ë¶„ì„ê¸° - JSON ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì—ì„œ ì˜ìƒ ê¸¸ì´ í†µê³„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
    )
    parser.add_argument(
        '--base-path',
        default='data/uploads',
        help='ì—…ë¡œë“œ í´ë”ë“¤ì´ ìˆëŠ” ê¸°ë³¸ ê²½ë¡œ (ê¸°ë³¸ê°’: data/uploads)'
    )
    parser.add_argument(
        '--output-dir',
        default='stats_output',
        help='í†µê³„ ê²°ê³¼ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: stats_output)'
    )
    parser.add_argument(
        '--start-date',
        help='ì‹œì‘ ë‚ ì§œ (YYYYMMDD í˜•ì‹, ì˜ˆ: 20250901)'
    )
    parser.add_argument(
        '--end-date',
        help='ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD í˜•ì‹, ì˜ˆ: 20250930)'
    )
    parser.add_argument(
        '--list',
        action='store_true',
        help='í´ë” ëª©ë¡ë§Œ ì¶œë ¥'
    )
    parser.add_argument(
        '--reprocess',
        action='store_true',
        help='ì´ë¯¸ ì²˜ë¦¬ëœ í´ë”ë„ ë‹¤ì‹œ ì²˜ë¦¬'
    )
    
    args = parser.parse_args()
    
    # ë¶„ì„ê¸° ìƒì„±
    analyzer = VideoStatsAnalyzer(
        base_path=args.base_path,
        output_dir=args.output_dir
    )
    
    # í´ë” ëª©ë¡ë§Œ ì¶œë ¥
    if args.list:
        analyzer.list_folders(
            start_date=args.start_date,
            end_date=args.end_date
        )
    # ë¶„ì„ ì‹¤í–‰
    else:
        analyzer.analyze_folders(
            start_date=args.start_date,
            end_date=args.end_date,
            skip_processed=not args.reprocess
        )


if __name__ == "__main__":
    main()

