"""
S3 File Transfer Utility
=========================

S3 í˜¸í™˜ ìŠ¤í† ë¦¬ì§€ì™€ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œ ê°„ íŒŒì¼ ì—…ë¡œë“œ/ë‹¤ìš´ë¡œë“œë¥¼ ìˆ˜í–‰í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
(AWS S3, Naver Cloud Platform, MinIO ë“± S3 í˜¸í™˜ ìŠ¤í† ë¦¬ì§€ ì§€ì›)

ì‚¬ìš©ë²• (Usage)
-------------

1. ì—…ë¡œë“œ (Upload)
   
   # ì „ì²´ í´ë” ì—…ë¡œë“œ
   $ python s3_file_transfer.py upload --local-path ./my_folder --s3-path my-project/data
   
   # íŠ¹ì • í´ë”ë“¤ë§Œ ì„ íƒ ì—…ë¡œë“œ
   $ python s3_file_transfer.py upload --local-path ./workers \
       --s3-path project/output \
       --folders folder1 folder2 folder3

2. ë‹¤ìš´ë¡œë“œ (Download)
   
   # S3 í´ë” ì „ì²´ ë‹¤ìš´ë¡œë“œ
   $ python s3_file_transfer.py download --s3-path my-project/data --local-path ./downloads
   
   # íŠ¹ì • íŒŒì¼ë§Œ ë‹¤ìš´ë¡œë“œ
   $ python s3_file_transfer.py download --s3-path my-project/data/file.txt --local-path ./downloads

3. ëª©ë¡ ì¡°íšŒ (List)
   
   # S3 ê²½ë¡œì˜ íŒŒì¼/í´ë” ëª©ë¡ ì¶œë ¥
   $ python s3_file_transfer.py list --s3-path my-project/data
   
   # ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  íŒŒì¼ ì¶œë ¥
   $ python s3_file_transfer.py list --s3-path my-project/data --recursive

ì„¤ì • (Configuration)
--------------------

í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” .env íŒŒì¼ì— ë‹¤ìŒ ì„¤ì •ì„ ì¶”ê°€í•˜ì„¸ìš”:

S3_ENDPOINT_URL=https://s3.amazonaws.com  (AWS S3ëŠ” ìƒëµ ê°€ëŠ¥)
S3_REGION=us-east-1
S3_ACCESS_KEY=your-access-key
S3_SECRET_KEY=your-secret-key
S3_BUCKET_NAME=your-bucket-name

AWS S3 ì‚¬ìš© ì‹œ:
  - S3_ENDPOINT_URLì€ ìƒëµ (ë˜ëŠ” ë¹„ì›Œë‘ê¸°)
  
Naver Cloud Platform ì‚¬ìš© ì‹œ:
  - S3_ENDPOINT_URL=https://kr.object.ncloudstorage.com
  - S3_REGION=kr-standard

ì˜µì…˜ (Options)
--------------
  --endpoint-url URL    S3 ì—”ë“œí¬ì¸íŠ¸ (í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • ê¶Œì¥)
  --region REGION       ë¦¬ì „ ì´ë¦„ (ê¸°ë³¸ê°’: us-east-1)
  --bucket BUCKET       ë²„í‚· ì´ë¦„ (í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • ê¶Œì¥)
  --local-path PATH     ë¡œì»¬ íŒŒì¼/í´ë” ê²½ë¡œ
  --s3-path PATH        S3 ê²½ë¡œ (ë²„í‚· ë‚´ ê²½ë¡œ)
  --folders NAMES       ì„ íƒì  ì—…ë¡œë“œí•  í´ë”ëª… (ê³µë°±ìœ¼ë¡œ êµ¬ë¶„)
  --recursive           ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬
  --dry-run             ì‹¤ì œ ì „ì†¡ ì—†ì´ ë¯¸ë¦¬ë³´ê¸°ë§Œ ìˆ˜í–‰
  -h, --help            ë„ì›€ë§ ì¶œë ¥

ì˜ˆì œ (Examples)
---------------

# 1. AWS S3ì— í´ë” ì—…ë¡œë“œ
$ export S3_BUCKET_NAME=my-bucket
$ export S3_ACCESS_KEY=AKIAXXXXXXXX
$ export S3_SECRET_KEY=xxxxxx
$ python s3_file_transfer.py upload --local-path ./data --s3-path project/data

# 2. NCP Object Storageì—ì„œ ë‹¤ìš´ë¡œë“œ
$ export S3_ENDPOINT_URL=https://kr.object.ncloudstorage.com
$ export S3_REGION=kr-standard
$ export S3_BUCKET_NAME=my-bucket
$ python s3_file_transfer.py download --s3-path project/data --local-path ./downloads

# 3. ì„ íƒì  í´ë” ì—…ë¡œë“œ
$ python s3_file_transfer.py upload \
    --local-path ./workers \
    --s3-path output/20250101 \
    --folders worker1 worker2 worker3

# 4. S3 ëª©ë¡ ì¡°íšŒ
$ python s3_file_transfer.py list --s3-path project/data --recursive

Author: [Your Name]
License: MIT
"""

import os
import sys
import boto3
from botocore.config import Config
from botocore.exceptions import ClientError
from datetime import datetime
from pathlib import Path
from typing import List, Optional
import argparse

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # .env íŒŒì¼ì´ ì—†ì–´ë„ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥


class S3FileTransfer:
    """S3 í˜¸í™˜ ìŠ¤í† ë¦¬ì§€ì™€ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œ ê°„ íŒŒì¼ ì „ì†¡"""
    
    def __init__(
        self,
        endpoint_url: Optional[str] = None,
        region: str = "us-east-1",
        access_key: Optional[str] = None,
        secret_key: Optional[str] = None,
        bucket_name: Optional[str] = None
    ):
        """
        Args:
            endpoint_url: S3 ì—”ë“œí¬ì¸íŠ¸ URL (AWS S3ëŠ” None)
            region: ë¦¬ì „ ì´ë¦„
            access_key: Access Key
            secret_key: Secret Key
            bucket_name: ë²„í‚· ì´ë¦„
        """
        self.endpoint_url = endpoint_url or os.getenv("S3_ENDPOINT_URL")
        self.region = region or os.getenv("S3_REGION", "us-east-1")
        self.bucket_name = bucket_name or os.getenv("S3_BUCKET_NAME")
        
        access_key = access_key or os.getenv("S3_ACCESS_KEY")
        secret_key = secret_key or os.getenv("S3_SECRET_KEY")
        
        if not all([access_key, secret_key, self.bucket_name]):
            raise ValueError(
                "S3 ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” .env íŒŒì¼ì— "
                "S3_ACCESS_KEY, S3_SECRET_KEY, S3_BUCKET_NAMEì„ ì„¤ì •í•˜ì„¸ìš”."
            )
        
        # S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        client_config = {
            "service_name": "s3",
            "region_name": self.region,
            "aws_access_key_id": access_key,
            "aws_secret_access_key": secret_key,
            "config": Config(s3={"addressing_style": "path"})
        }
        
        if self.endpoint_url:
            client_config["endpoint_url"] = self.endpoint_url
        
        self.s3 = boto3.client(**client_config)
        
        print(f"ğŸ”— S3 ì—°ê²°:")
        if self.endpoint_url:
            print(f"   Endpoint: {self.endpoint_url}")
        print(f"   Region: {self.region}")
        print(f"   Bucket: {self.bucket_name}\n")
    
    def upload_file(self, local_path: str, s3_key: str, dry_run: bool = False) -> bool:
        """
        ë‹¨ì¼ íŒŒì¼ì„ S3ì— ì—…ë¡œë“œ
        
        Args:
            local_path: ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
            s3_key: S3 í‚¤ (ë²„í‚· ë‚´ ê²½ë¡œ)
            dry_run: Trueë©´ ì‹¤ì œ ì—…ë¡œë“œ ì—†ì´ ë¯¸ë¦¬ë³´ê¸°ë§Œ
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            file_size = os.path.getsize(local_path)
            
            if dry_run:
                print(f"   [DRY-RUN] {local_path} -> s3://{self.bucket_name}/{s3_key}")
                return True
            
            self.s3.upload_file(local_path, self.bucket_name, s3_key)
            print(f"   âœ“ {os.path.basename(local_path)} ({file_size / (1024*1024):.2f} MB)")
            return True
            
        except Exception as e:
            print(f"   âŒ {os.path.basename(local_path)}: {e}")
            return False
    
    def upload_folder(
        self,
        local_root: str,
        s3_base_path: str,
        dry_run: bool = False
    ) -> dict:
        """
        í´ë” ì „ì²´ë¥¼ S3ì— ì—…ë¡œë“œ
        
        Args:
            local_root: ë¡œì»¬ í´ë” ê²½ë¡œ
            s3_base_path: S3 ê¸°ë³¸ ê²½ë¡œ
            dry_run: Trueë©´ ì‹¤ì œ ì—…ë¡œë“œ ì—†ì´ ë¯¸ë¦¬ë³´ê¸°ë§Œ
            
        Returns:
            ì—…ë¡œë“œ í†µê³„ (uploaded_count, total_size, elapsed_time)
        """
        if not os.path.exists(local_root):
            print(f"âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {local_root}")
            return {"uploaded_count": 0, "total_size": 0}
        
        upload_start_time = datetime.now()
        uploaded_count = 0
        total_size = 0
        
        print(f"\n{'='*70}")
        print(f"ğŸ“ {'[DRY-RUN] ' if dry_run else ''}í´ë” ì—…ë¡œë“œ")
        print(f"{'='*70}")
        print(f"ğŸ“‚ ë¡œì»¬: {local_root}")
        print(f"â˜ï¸  S3:   s3://{self.bucket_name}/{s3_base_path}/\n")
        
        for root, dirs, files in os.walk(local_root):
            for file in files:
                local_path = os.path.join(root, file)
                relative_path = os.path.relpath(local_path, local_root)
                s3_key = f"{s3_base_path}/{relative_path}".replace(os.sep, "/")
                
                file_size = os.path.getsize(local_path)
                total_size += file_size
                
                if self.upload_file(local_path, s3_key, dry_run):
                    uploaded_count += 1
        
        elapsed = datetime.now() - upload_start_time
        
        print(f"\n{'='*70}")
        print(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ!")
        print(f"{'='*70}")
        print(f"ğŸ“Š íŒŒì¼ ê°œìˆ˜: {uploaded_count}ê°œ")
        print(f"ğŸ“¦ ì´ í¬ê¸°: {total_size / (1024*1024*1024):.2f} GB")
        print(f"â±ï¸  ì†Œìš”ì‹œê°„: {elapsed}\n")
        
        return {
            "uploaded_count": uploaded_count,
            "total_size": total_size,
            "elapsed_time": elapsed
        }
    
    def upload_specific_folders(
        self,
        base_dir: str,
        folder_names: List[str],
        s3_base_path: str,
        dry_run: bool = False
    ) -> dict:
        """
        íŠ¹ì • í´ë”ë“¤ë§Œ ì„ íƒì ìœ¼ë¡œ ì—…ë¡œë“œ
        
        Args:
            base_dir: ê¸°ë³¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            folder_names: ì—…ë¡œë“œí•  í´ë”ëª… ë¦¬ìŠ¤íŠ¸
            s3_base_path: S3 ê¸°ë³¸ ê²½ë¡œ
            dry_run: Trueë©´ ì‹¤ì œ ì—…ë¡œë“œ ì—†ì´ ë¯¸ë¦¬ë³´ê¸°ë§Œ
            
        Returns:
            ì—…ë¡œë“œ í†µê³„
        """
        print(f"\n{'='*70}")
        print(f"ğŸ¯ {'[DRY-RUN] ' if dry_run else ''}ì„ íƒì  í´ë” ì—…ë¡œë“œ")
        print(f"{'='*70}")
        print(f"ğŸ“‚ ê¸°ë³¸ ê²½ë¡œ: {base_dir}")
        print(f"ğŸ“‹ ëŒ€ìƒ í´ë”: {', '.join(folder_names)}\n")
        
        total_uploaded = 0
        total_size = 0
        upload_start_time = datetime.now()
        
        for folder_name in folder_names:
            folder_path = os.path.join(base_dir, folder_name)
            
            if not os.path.exists(folder_path):
                print(f"â— í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {folder_name}")
                continue
            
            if not os.path.isdir(folder_path):
                print(f"â— ë””ë ‰í† ë¦¬ê°€ ì•„ë‹˜: {folder_name}")
                continue
            
            print(f"\nğŸ“ [{folder_name}] ì—…ë¡œë“œ ì¤‘...")
            
            folder_uploaded = 0
            folder_size = 0
            
            for root, dirs, files in os.walk(folder_path):
                for file in files:
                    local_path = os.path.join(root, file)
                    relative_path = os.path.relpath(local_path, folder_path)
                    s3_key = f"{s3_base_path}/{folder_name}/{relative_path}".replace(os.sep, "/")
                    
                    file_size = os.path.getsize(local_path)
                    folder_size += file_size
                    
                    if self.upload_file(local_path, s3_key, dry_run):
                        folder_uploaded += 1
                        total_uploaded += 1
                        total_size += file_size
            
            print(f"   âœ… {folder_name}: {folder_uploaded}ê°œ íŒŒì¼ ({folder_size / (1024*1024):.2f} MB)")
        
        elapsed = datetime.now() - upload_start_time
        
        print(f"\n{'='*70}")
        print(f"âœ… ëª¨ë“  ì—…ë¡œë“œ ì™„ë£Œ!")
        print(f"{'='*70}")
        print(f"ğŸ“Š ì´ íŒŒì¼: {total_uploaded}ê°œ")
        print(f"ğŸ“¦ ì´ í¬ê¸°: {total_size / (1024*1024*1024):.2f} GB")
        print(f"â±ï¸  ì†Œìš”ì‹œê°„: {elapsed}\n")
        
        return {
            "uploaded_count": total_uploaded,
            "total_size": total_size,
            "elapsed_time": elapsed
        }
    
    def download_file(self, s3_key: str, local_path: str, dry_run: bool = False) -> bool:
        """
        S3ì—ì„œ ë‹¨ì¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        
        Args:
            s3_key: S3 í‚¤
            local_path: ë¡œì»¬ ì €ì¥ ê²½ë¡œ
            dry_run: Trueë©´ ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ì—†ì´ ë¯¸ë¦¬ë³´ê¸°ë§Œ
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            if dry_run:
                print(f"   [DRY-RUN] s3://{self.bucket_name}/{s3_key} -> {local_path}")
                return True
            
            # ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(os.path.dirname(local_path), exist_ok=True)
            
            self.s3.download_file(self.bucket_name, s3_key, local_path)
            file_size = os.path.getsize(local_path)
            print(f"   âœ“ {os.path.basename(local_path)} ({file_size / (1024*1024):.2f} MB)")
            return True
            
        except Exception as e:
            print(f"   âŒ {os.path.basename(local_path)}: {e}")
            return False
    
    def download_folder(
        self,
        s3_prefix: str,
        local_root: str,
        dry_run: bool = False
    ) -> dict:
        """
        S3 í´ë” ì „ì²´ë¥¼ ë¡œì»¬ë¡œ ë‹¤ìš´ë¡œë“œ
        
        Args:
            s3_prefix: S3 ê²½ë¡œ í”„ë¦¬í”½ìŠ¤
            local_root: ë¡œì»¬ ì €ì¥ ê²½ë¡œ
            dry_run: Trueë©´ ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ì—†ì´ ë¯¸ë¦¬ë³´ê¸°ë§Œ
            
        Returns:
            ë‹¤ìš´ë¡œë“œ í†µê³„
        """
        download_start_time = datetime.now()
        downloaded_count = 0
        total_size = 0
        
        print(f"\n{'='*70}")
        print(f"ğŸ“¥ {'[DRY-RUN] ' if dry_run else ''}í´ë” ë‹¤ìš´ë¡œë“œ")
        print(f"{'='*70}")
        print(f"â˜ï¸  S3:   s3://{self.bucket_name}/{s3_prefix}/")
        print(f"ğŸ“‚ ë¡œì»¬: {local_root}\n")
        
        try:
            paginator = self.s3.get_paginator('list_objects_v2')
            pages = paginator.paginate(Bucket=self.bucket_name, Prefix=s3_prefix)
            
            for page in pages:
                if 'Contents' not in page:
                    continue
                
                for obj in page['Contents']:
                    s3_key = obj['Key']
                    relative_path = os.path.relpath(s3_key, s3_prefix)
                    local_path = os.path.join(local_root, relative_path)
                    
                    if self.download_file(s3_key, local_path, dry_run):
                        downloaded_count += 1
                        if not dry_run:
                            total_size += os.path.getsize(local_path)
            
            elapsed = datetime.now() - download_start_time
            
            print(f"\n{'='*70}")
            print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
            print(f"{'='*70}")
            print(f"ğŸ“Š íŒŒì¼ ê°œìˆ˜: {downloaded_count}ê°œ")
            print(f"ğŸ“¦ ì´ í¬ê¸°: {total_size / (1024*1024*1024):.2f} GB")
            print(f"â±ï¸  ì†Œìš”ì‹œê°„: {elapsed}\n")
            
            return {
                "downloaded_count": downloaded_count,
                "total_size": total_size,
                "elapsed_time": elapsed
            }
            
        except Exception as e:
            print(f"âŒ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"downloaded_count": 0, "total_size": 0}
    
    def list_objects(self, s3_prefix: str = "", recursive: bool = False):
        """
        S3 ê²½ë¡œì˜ ê°ì²´ ëª©ë¡ ì¶œë ¥
        
        Args:
            s3_prefix: S3 ê²½ë¡œ í”„ë¦¬í”½ìŠ¤
            recursive: Trueë©´ ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  íŒŒì¼ ì¶œë ¥
        """
        print(f"\n{'='*70}")
        print(f"ğŸ“‹ S3 ê°ì²´ ëª©ë¡")
        print(f"{'='*70}")
        print(f"â˜ï¸  ê²½ë¡œ: s3://{self.bucket_name}/{s3_prefix or '(root)'}\n")
        
        try:
            if recursive:
                # ëª¨ë“  íŒŒì¼ ë‚˜ì—´
                paginator = self.s3.get_paginator('list_objects_v2')
                pages = paginator.paginate(Bucket=self.bucket_name, Prefix=s3_prefix)
                
                total_count = 0
                total_size = 0
                
                for page in pages:
                    if 'Contents' not in page:
                        continue
                    
                    for obj in page['Contents']:
                        size_mb = obj['Size'] / (1024*1024)
                        modified = obj['LastModified'].strftime('%Y-%m-%d %H:%M:%S')
                        print(f"  ğŸ“„ {obj['Key']}")
                        print(f"      í¬ê¸°: {size_mb:.2f} MB | ìˆ˜ì •ì¼: {modified}")
                        total_count += 1
                        total_size += obj['Size']
                
                print(f"\n{'='*70}")
                print(f"ğŸ“Š ì´ íŒŒì¼: {total_count}ê°œ")
                print(f"ğŸ“¦ ì´ í¬ê¸°: {total_size / (1024*1024*1024):.2f} GB\n")
                
            else:
                # ë””ë ‰í† ë¦¬ êµ¬ì¡°ë§Œ ë‚˜ì—´
                response = self.s3.list_objects_v2(
                    Bucket=self.bucket_name,
                    Prefix=s3_prefix,
                    Delimiter='/'
                )
                
                # í´ë” ì¶œë ¥
                if 'CommonPrefixes' in response:
                    print("ğŸ“ í´ë”:")
                    for prefix in response['CommonPrefixes']:
                        folder_name = prefix['Prefix'].rstrip('/').split('/')[-1]
                        print(f"  ğŸ“ {folder_name}/")
                
                # íŒŒì¼ ì¶œë ¥
                if 'Contents' in response:
                    print("\nğŸ“„ íŒŒì¼:")
                    for obj in response['Contents']:
                        if obj['Key'] == s3_prefix:  # í”„ë¦¬í”½ìŠ¤ ìì²´ëŠ” ì œì™¸
                            continue
                        file_name = obj['Key'].split('/')[-1]
                        size_mb = obj['Size'] / (1024*1024)
                        print(f"  ğŸ“„ {file_name} ({size_mb:.2f} MB)")
                
                print()
                
        except Exception as e:
            print(f"âŒ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="S3 íŒŒì¼ ì „ì†¡ ìœ í‹¸ë¦¬í‹° - ì—…ë¡œë“œ/ë‹¤ìš´ë¡œë“œ/ëª©ë¡ì¡°íšŒ",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    subparsers = parser.add_subparsers(dest='command', help='ëª…ë ¹ì–´')
    
    # ê³µí†µ ì¸ì
    common = argparse.ArgumentParser(add_help=False)
    common.add_argument('--endpoint-url', help='S3 ì—”ë“œí¬ì¸íŠ¸ URL')
    common.add_argument('--region', default='us-east-1', help='ë¦¬ì „ (ê¸°ë³¸ê°’: us-east-1)')
    common.add_argument('--bucket', help='ë²„í‚· ì´ë¦„')
    common.add_argument('--dry-run', action='store_true', help='ì‹¤ì œ ì „ì†¡ ì—†ì´ ë¯¸ë¦¬ë³´ê¸°ë§Œ')
    
    # upload ëª…ë ¹ì–´
    upload_parser = subparsers.add_parser('upload', parents=[common], help='íŒŒì¼/í´ë” ì—…ë¡œë“œ')
    upload_parser.add_argument('--local-path', required=True, help='ë¡œì»¬ ê²½ë¡œ')
    upload_parser.add_argument('--s3-path', required=True, help='S3 ê²½ë¡œ')
    upload_parser.add_argument('--folders', nargs='+', help='ì„ íƒì  ì—…ë¡œë“œí•  í´ë”ëª…')
    
    # download ëª…ë ¹ì–´
    download_parser = subparsers.add_parser('download', parents=[common], help='íŒŒì¼/í´ë” ë‹¤ìš´ë¡œë“œ')
    download_parser.add_argument('--s3-path', required=True, help='S3 ê²½ë¡œ')
    download_parser.add_argument('--local-path', required=True, help='ë¡œì»¬ ì €ì¥ ê²½ë¡œ')
    
    # list ëª…ë ¹ì–´
    list_parser = subparsers.add_parser('list', parents=[common], help='S3 ê°ì²´ ëª©ë¡')
    list_parser.add_argument('--s3-path', default='', help='S3 ê²½ë¡œ')
    list_parser.add_argument('--recursive', action='store_true', help='ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  íŒŒì¼ ì¶œë ¥')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    try:
        # S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        transfer = S3FileTransfer(
            endpoint_url=args.endpoint_url,
            region=args.region,
            bucket_name=args.bucket
        )
        
        # ëª…ë ¹ì–´ ì‹¤í–‰
        if args.command == 'upload':
            if args.folders:
                # ì„ íƒì  í´ë” ì—…ë¡œë“œ
                transfer.upload_specific_folders(
                    args.local_path,
                    args.folders,
                    args.s3_path,
                    args.dry_run
                )
            else:
                # ì „ì²´ í´ë” ì—…ë¡œë“œ
                transfer.upload_folder(
                    args.local_path,
                    args.s3_path,
                    args.dry_run
                )
        
        elif args.command == 'download':
            transfer.download_folder(
                args.s3_path,
                args.local_path,
                args.dry_run
            )
        
        elif args.command == 'list':
            transfer.list_objects(args.s3_path, args.recursive)
    
    except ValueError as e:
        print(f"âŒ ì„¤ì • ì˜¤ë¥˜: {e}")
        print("\ní™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ .env íŒŒì¼ì„ ìƒì„±í•˜ì„¸ìš”:")
        print("  S3_ACCESS_KEY=your-access-key")
        print("  S3_SECRET_KEY=your-secret-key")
        print("  S3_BUCKET_NAME=your-bucket-name")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
