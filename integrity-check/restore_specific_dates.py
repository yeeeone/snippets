"""
JSON Field Value Fixer
=======================

JSON íŒŒì¼ì—ì„œ íŠ¹ì • í•„ë“œì˜ ì˜ëª»ëœ ê°’ì„ ì°¾ì•„ì„œ ì˜¬ë°”ë¥¸ ê°’ìœ¼ë¡œ ì¼ê´„ ìˆ˜ì •í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.

ì‚¬ìš©ë²• (Usage)
-------------

1. ê¸°ë³¸ ì‚¬ìš© (íŠ¹ì • ê°’ ìˆ˜ì •)
   $ python json_field_fixer.py \
       --path ./data/uploads/upload_20251219_001 \
       --field program_broadcasted_at \
       --find 20169715 \
       --replace 20160715

2. ì—¬ëŸ¬ ê°’ ë™ì‹œ ìˆ˜ì •
   $ python json_field_fixer.py \
       --path ./data \
       --field date \
       --find 20169715 130416-18 20251300 \
       --replace 20160715

3. ì—¬ëŸ¬ í´ë” ì¼ê´„ ìˆ˜ì •
   $ python json_field_fixer.py \
       --path ./uploads \
       --folders upload_20251219_001 upload_20251220_001 \
       --field program_broadcasted_at \
       --find 20169715 \
       --replace 20160715

4. ë¯¸ë¦¬ë³´ê¸° ëª¨ë“œ (ì‹¤ì œ ìˆ˜ì • ì•ˆí•¨)
   $ python json_field_fixer.py \
       --path ./data \
       --field date \
       --find 20169715 \
       --replace 20160715 \
       --dry-run

5. ë°±ì—… ì—†ì´ ìˆ˜ì • (ì£¼ì˜!)
   $ python json_field_fixer.py \
       --path ./data \
       --field date \
       --find 20169715 \
       --replace 20160715 \
       --no-backup

ê¸°ëŠ¥ (Features)
---------------
âœ“ íŠ¹ì • ê°’ì„ ê°€ì§„ íŒŒì¼ ìë™ ê²€ìƒ‰
âœ“ ì—¬ëŸ¬ ê°’ì„ ë™ì¼í•œ ê°’ìœ¼ë¡œ ì¼ê´„ ìˆ˜ì •
âœ“ ìˆ˜ì • ì „ ìë™ ë°±ì—… ìƒì„±
âœ“ Dry-run ëª¨ë“œë¡œ ë¯¸ë¦¬ë³´ê¸°
âœ“ ìƒì„¸í•œ ìˆ˜ì • ë¡œê·¸ ìƒì„±
âœ“ ì¬ê·€ì  í´ë” íƒìƒ‰ ì§€ì›

ë°±ì—… (Backup)
-------------
ê¸°ë³¸ì ìœ¼ë¡œ ìˆ˜ì • ì „ ì›ë³¸ íŒŒì¼ì„ ë°±ì—…í•©ë‹ˆë‹¤:
- ë°±ì—… ìœ„ì¹˜: {íŒŒì¼ëª…}_backup_{timestamp}.json
- ë°±ì—… ë¹„í™œì„±í™”: --no-backup ì˜µì…˜ ì‚¬ìš©

ì¶œë ¥ (Output)
-------------
fix_results/
â”œâ”€â”€ fix_log_{timestamp}.txt          # ìˆ˜ì • ë¡œê·¸
â”œâ”€â”€ fix_log_{timestamp}.json         # JSON í˜•ì‹ ë¡œê·¸
â””â”€â”€ fix_summary_{timestamp}.txt      # ìš”ì•½ í†µê³„

ë””ë ‰í† ë¦¬ êµ¬ì¡° (Directory Structure)
-----------------------------------
project/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ uploads/
â”‚       â”œâ”€â”€ upload_20251219_001/
â”‚       â”‚   â”œâ”€â”€ file1.json
â”‚       â”‚   â”œâ”€â”€ file1_backup_20250106.json  # ë°±ì—…
â”‚       â”‚   â””â”€â”€ file2.json
â”‚       â””â”€â”€ upload_20251220_001/
â”œâ”€â”€ fix_results/  # ìë™ ìƒì„±
â””â”€â”€ json_field_fixer.py

ì˜µì…˜ (Options)
--------------
  --path PATH              JSON íŒŒì¼ì´ ìˆëŠ” ê¸°ë³¸ ê²½ë¡œ (í•„ìˆ˜)
  --folders NAMES          ìˆ˜ì •í•  íŠ¹ì • í´ë”ëª… (ì„ íƒ)
  --field FIELD            ìˆ˜ì •í•  í•„ë“œëª… (í•„ìˆ˜)
  --find VALUES            ì°¾ì„ ê°’ë“¤ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)
  --replace VALUE          ë³€ê²½í•  ê°’ (í•„ìˆ˜)
  --output-dir DIR         ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: fix_results)
  --recursive              í•˜ìœ„ í´ë”ê¹Œì§€ ì¬ê·€ ê²€ìƒ‰
  --dry-run                ì‹¤ì œ ìˆ˜ì • ì—†ì´ ë¯¸ë¦¬ë³´ê¸°ë§Œ
  --no-backup              ë°±ì—… íŒŒì¼ ìƒì„± ì•ˆí•¨
  --quiet                  ìµœì†Œí•œì˜ ì¶œë ¥ë§Œ í‘œì‹œ
  -h, --help               ë„ì›€ë§ ì¶œë ¥

ì˜ˆì œ (Examples)
---------------

# 1. ë‚ ì§œ ì˜¤íƒ€ ìˆ˜ì • (20169715 â†’ 20160715)
$ python json_field_fixer.py \
    --path ./uploads/upload_20251219_001 \
    --field program_broadcasted_at \
    --find 20169715 \
    --replace 20160715

# 2. ì—¬ëŸ¬ ì˜¤íƒ€ë¥¼ í•œ ë²ˆì— ìˆ˜ì •
$ python json_field_fixer.py \
    --path ./data \
    --field date \
    --find 20169715 130416-18 20251300 \
    --replace 20160715

# 3. ë¯¸ë¦¬ë³´ê¸° í›„ ìˆ˜ì •
$ python json_field_fixer.py --path ./data --field date \
    --find 20169715 --replace 20160715 --dry-run

# ì‹¤ì œ ìˆ˜ì •
$ python json_field_fixer.py --path ./data --field date \
    --find 20169715 --replace 20160715

# 4. ì—¬ëŸ¬ í´ë” ì¼ê´„ ìˆ˜ì •
$ python json_field_fixer.py \
    --path ./uploads \
    --folders folder1 folder2 folder3 \
    --field program_broadcasted_at \
    --find 20169715 \
    --replace 20160715

ì£¼ì˜ì‚¬í•­ (Cautions)
-------------------
âš ï¸ --no-backup ì˜µì…˜ ì‚¬ìš© ì‹œ ì›ë³¸ íŒŒì¼ì´ ì˜êµ¬ì ìœ¼ë¡œ ìˆ˜ì •ë©ë‹ˆë‹¤
âš ï¸ ìˆ˜ì • ì „ì—ëŠ” ë°˜ë“œì‹œ --dry-runìœ¼ë¡œ í™•ì¸í•˜ì„¸ìš”
âœ“ ê¸°ë³¸ì ìœ¼ë¡œ ë°±ì—…ì´ ìë™ ìƒì„±ë˜ë¯€ë¡œ ì•ˆì „í•©ë‹ˆë‹¤

"""

import os
import json
import argparse
import shutil
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional
from collections import defaultdict


class JSONFieldFixer:
    """JSON íŒŒì¼ì˜ íŠ¹ì • í•„ë“œ ê°’ì„ ìˆ˜ì •í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        base_path: str,
        output_dir: str = "fix_results",
        backup: bool = True,
        dry_run: bool = False,
        quiet: bool = False
    ):
        """
        Args:
            base_path: JSON íŒŒì¼ì´ ìˆëŠ” ê¸°ë³¸ ê²½ë¡œ
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
            backup: ë°±ì—… ìƒì„± ì—¬ë¶€
            dry_run: Trueë©´ ì‹¤ì œ ìˆ˜ì • ì—†ì´ ë¯¸ë¦¬ë³´ê¸°ë§Œ
            quiet: Trueë©´ ìµœì†Œí•œì˜ ì¶œë ¥ë§Œ
        """
        self.base_path = Path(base_path)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True, parents=True)
        
        self.backup = backup
        self.dry_run = dry_run
        self.quiet = quiet
        
        if not self.base_path.exists():
            raise ValueError(f"ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.base_path}")
    
    def log(self, message: str, force: bool = False):
        """ë¡œê·¸ ì¶œë ¥ (quiet ëª¨ë“œ ê³ ë ¤)"""
        if not self.quiet or force:
            print(message)
    
    def get_json_files(
        self,
        folder_path: Path,
        recursive: bool = False
    ) -> List[Path]:
        """
        í´ë”ì—ì„œ JSON íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤
        
        Args:
            folder_path: íƒìƒ‰í•  í´ë” ê²½ë¡œ
            recursive: Trueë©´ í•˜ìœ„ í´ë”ê¹Œì§€ ì¬ê·€ íƒìƒ‰
            
        Returns:
            JSON íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        if recursive:
            return list(folder_path.rglob("*.json"))
        else:
            return list(folder_path.glob("*.json"))
    
    def scan_for_target_values(
        self,
        folder_path: Path,
        field_name: str,
        target_values: List[str],
        recursive: bool = False
    ) -> Dict[Path, str]:
        """
        íŠ¹ì • í•„ë“œì—ì„œ ëŒ€ìƒ ê°’ì„ ê°€ì§„ íŒŒì¼ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤
        
        Args:
            folder_path: ìŠ¤ìº”í•  í´ë” ê²½ë¡œ
            field_name: ê²€ìƒ‰í•  í•„ë“œëª…
            target_values: ì°¾ì„ ê°’ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
            recursive: ì¬ê·€ íƒìƒ‰ ì—¬ë¶€
            
        Returns:
            {íŒŒì¼ ê²½ë¡œ: í˜„ì¬ ê°’} ë”•ì…”ë„ˆë¦¬
        """
        file_data = {}
        json_files = self.get_json_files(folder_path, recursive)
        
        self.log(f"ğŸ“– í´ë” ìŠ¤ìº” ì¤‘: {folder_path}")
        self.log(f"   JSON íŒŒì¼: {len(json_files)}ê°œ\n")
        
        scanned_count = 0
        
        for json_file in json_files:
            scanned_count += 1
            
            if scanned_count % 100 == 0:
                self.log(f"   [{scanned_count}/{len(json_files)}] ìŠ¤ìº” ì¤‘...")
            
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                value = data.get(field_name, '')
                
                # ëŒ€ìƒ ê°’ì¸ì§€ í™•ì¸
                if str(value) in target_values:
                    file_data[json_file] = value
                    self.log(f"   âœ… ë°œê²¬: {json_file.name} = {value}")
            
            except Exception as e:
                self.log(f"   âš ï¸ ì½ê¸° ì˜¤ë¥˜ ({json_file.name}): {e}")
                continue
        
        self.log(f"\n   âœ… ìŠ¤ìº” ì™„ë£Œ: {scanned_count}ê°œ ê²€ì‚¬, {len(file_data)}ê°œ ë°œê²¬\n")
        return file_data
    
    def backup_file(self, file_path: Path) -> Optional[Path]:
        """
        íŒŒì¼ ë°±ì—… ìƒì„±
        
        Args:
            file_path: ë°±ì—…í•  íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ë°±ì—… íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
        """
        if not self.backup:
            return None
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = file_path.with_name(
            f"{file_path.stem}_backup_{timestamp}{file_path.suffix}"
        )
        
        try:
            shutil.copy2(file_path, backup_path)
            return backup_path
        except Exception as e:
            self.log(f"   âš ï¸ ë°±ì—… ì‹¤íŒ¨ ({file_path.name}): {e}")
            return None
    
    def fix_file(
        self,
        file_path: Path,
        field_name: str,
        target_values: List[str],
        new_value: str
    ) -> Dict:
        """
        ë‹¨ì¼ íŒŒì¼ì˜ í•„ë“œ ê°’ì„ ìˆ˜ì •í•©ë‹ˆë‹¤
        
        Args:
            file_path: ìˆ˜ì •í•  íŒŒì¼ ê²½ë¡œ
            field_name: ìˆ˜ì •í•  í•„ë“œëª…
            target_values: ëŒ€ìƒ ê°’ë“¤
            new_value: ë³€ê²½í•  ê°’
            
        Returns:
            ìˆ˜ì • ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        result = {
            'file': str(file_path),
            'file_name': file_path.name,
            'status': 'failed',
            'original_value': None,
            'new_value': new_value,
            'backup_path': None,
            'error': None
        }
        
        try:
            # íŒŒì¼ ì½ê¸°
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            original_value = data.get(field_name, '')
            result['original_value'] = original_value
            
            # ëŒ€ìƒ ê°’ì´ ì•„ë‹ˆë©´ ê±´ë„ˆë›°ê¸°
            if str(original_value) not in target_values:
                result['status'] = 'skipped'
                result['error'] = 'Not a target value'
                return result
            
            # Dry-run ëª¨ë“œ
            if self.dry_run:
                result['status'] = 'dry_run'
                return result
            
            # ë°±ì—… ìƒì„±
            if self.backup:
                backup_path = self.backup_file(file_path)
                if backup_path:
                    result['backup_path'] = str(backup_path)
            
            # ê°’ ìˆ˜ì •
            data[field_name] = new_value
            
            # íŒŒì¼ ì €ì¥
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            result['status'] = 'success'
        
        except Exception as e:
            result['error'] = str(e)
        
        return result
    
    def fix_folders(
        self,
        folder_names: Optional[List[str]],
        field_name: str,
        target_values: List[str],
        new_value: str,
        recursive: bool = False
    ) -> Dict:
        """
        í´ë”ë“¤ì˜ JSON íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤
        
        Args:
            folder_names: ìˆ˜ì •í•  í´ë”ëª… ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ base_path ì „ì²´)
            field_name: ìˆ˜ì •í•  í•„ë“œëª…
            target_values: ì°¾ì„ ê°’ë“¤
            new_value: ë³€ê²½í•  ê°’
            recursive: ì¬ê·€ íƒìƒ‰ ì—¬ë¶€
            
        Returns:
            ì „ì²´ ìˆ˜ì • ê²°ê³¼
        """
        self.log("="*70, force=True)
        self.log(f"ğŸ”§ {'[DRY-RUN] ' if self.dry_run else ''}JSON í•„ë“œ ê°’ ìˆ˜ì •", force=True)
        self.log("="*70, force=True)
        self.log(f"ğŸ“‚ ê¸°ë³¸ ê²½ë¡œ: {self.base_path}", force=True)
        self.log(f"ğŸ“‹ í•„ë“œ: {field_name}", force=True)
        self.log(f"ğŸ” ì°¾ì„ ê°’: {', '.join(target_values)}", force=True)
        self.log(f"âœï¸  ë³€ê²½ ê°’: {new_value}", force=True)
        self.log("")
        
        # í´ë” ëª©ë¡ ê²°ì •
        if folder_names:
            folders = [self.base_path / folder for folder in folder_names]
            folders = [f for f in folders if f.exists() and f.is_dir()]
            if not folders:
                self.log("âŒ ì§€ì •í•œ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", force=True)
                return {}
        else:
            folders = [self.base_path]
        
        all_results = []
        
        for folder in folders:
            self.log(f"1ï¸âƒ£ [{folder.name}] ëŒ€ìƒ íŒŒì¼ ê²€ìƒ‰\n", force=True)
            
            # ëŒ€ìƒ íŒŒì¼ ì°¾ê¸°
            target_files = self.scan_for_target_values(
                folder, field_name, target_values, recursive
            )
            
            if not target_files:
                self.log(f"   âš ï¸ ìˆ˜ì •í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\n")
                continue
            
            self.log(f"   ğŸ“ ìˆ˜ì • ëŒ€ìƒ: {len(target_files)}ê°œ íŒŒì¼\n", force=True)
            
            # íŒŒì¼ ìˆ˜ì •
            self.log(f"2ï¸âƒ£ íŒŒì¼ ìˆ˜ì • ì¤‘\n", force=True)
            
            success_count = 0
            failed_count = 0
            
            for idx, (file_path, original_value) in enumerate(target_files.items(), 1):
                if idx % 50 == 0 or idx == 1:
                    self.log(f"   [{idx}/{len(target_files)}] ì²˜ë¦¬ ì¤‘...")
                
                result = self.fix_file(file_path, field_name, target_values, new_value)
                all_results.append(result)
                
                if result['status'] == 'success' or result['status'] == 'dry_run':
                    success_count += 1
                else:
                    failed_count += 1
                    if result['error']:
                        self.log(f"      âš ï¸ ì‹¤íŒ¨ ({file_path.name}): {result['error']}")
            
            self.log(f"\n   âœ… ì²˜ë¦¬ ì™„ë£Œ", force=True)
            self.log(f"      {'ë¯¸ë¦¬ë³´ê¸°' if self.dry_run else 'ìˆ˜ì •'}: {success_count}ê°œ", force=True)
            self.log(f"      ì‹¤íŒ¨: {failed_count}ê°œ\n", force=True)
        
        return {
            'results': all_results,
            'field_name': field_name,
            'target_values': target_values,
            'new_value': new_value
        }
    
    def save_results(self, fix_data: Dict):
        """
        ìˆ˜ì • ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤
        
        Args:
            fix_data: ìˆ˜ì • ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results = fix_data['results']
        
        # í…ìŠ¤íŠ¸ ë¡œê·¸
        log_file = self.output_dir / f"fix_log_{timestamp}.txt"
        
        with open(log_file, 'w', encoding='utf-8') as f:
            f.write("="*70 + "\n")
            f.write("JSON í•„ë“œ ìˆ˜ì • ë¡œê·¸\n")
            f.write("="*70 + "\n")
            f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"í•„ë“œ: {fix_data['field_name']}\n")
            f.write(f"ì°¾ì€ ê°’: {', '.join(fix_data['target_values'])}\n")
            f.write(f"ë³€ê²½ ê°’: {fix_data['new_value']}\n")
            f.write(f"Dry-run: {'ì˜ˆ' if self.dry_run else 'ì•„ë‹ˆì˜¤'}\n")
            f.write("="*70 + "\n\n")
            
            # ì„±ê³µ
            success_results = [r for r in results if r['status'] in ['success', 'dry_run']]
            if success_results:
                f.write(f"âœ… {'ë¯¸ë¦¬ë³´ê¸°' if self.dry_run else 'ìˆ˜ì • ì™„ë£Œ'} ({len(success_results)}ê°œ):\n")
                f.write("-"*70 + "\n")
                for result in success_results:
                    f.write(f"íŒŒì¼: {result['file_name']}\n")
                    f.write(f"  ë³€ê²½ ì „: {result['original_value']}\n")
                    f.write(f"  ë³€ê²½ í›„: {result['new_value']}\n")
                    if result['backup_path']:
                        f.write(f"  ë°±ì—…: {result['backup_path']}\n")
                    f.write("\n")
            
            # ì‹¤íŒ¨
            failed_results = [r for r in results if r['status'] == 'failed']
            if failed_results:
                f.write(f"\nâŒ ì‹¤íŒ¨ ({len(failed_results)}ê°œ):\n")
                f.write("-"*70 + "\n")
                for result in failed_results:
                    f.write(f"íŒŒì¼: {result['file_name']}\n")
                    f.write(f"  ì˜¤ë¥˜: {result['error']}\n\n")
            
            # í†µê³„
            f.write("="*70 + "\n")
            f.write("í†µê³„\n")
            f.write("="*70 + "\n")
            f.write(f"ì „ì²´: {len(results)}ê°œ\n")
            f.write(f"{'ë¯¸ë¦¬ë³´ê¸°' if self.dry_run else 'ìˆ˜ì •'}: {len(success_results)}ê°œ\n")
            f.write(f"ì‹¤íŒ¨: {len(failed_results)}ê°œ\n")
        
        # JSON ë¡œê·¸
        json_file = self.output_dir / f"fix_log_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(fix_data, f, indent=2, ensure_ascii=False)
        
        # ìš”ì•½
        summary_file = self.output_dir / f"fix_summary_{timestamp}.txt"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("="*70 + "\n")
            f.write("ìˆ˜ì • ìš”ì•½\n")
            f.write("="*70 + "\n\n")
            f.write(f"í•„ë“œ: {fix_data['field_name']}\n")
            f.write(f"ëŒ€ìƒ ê°’: {', '.join(fix_data['target_values'])}\n")
            f.write(f"ë³€ê²½ ê°’: {fix_data['new_value']}\n\n")
            f.write(f"ì „ì²´: {len(results)}ê°œ\n")
            f.write(f"{'ë¯¸ë¦¬ë³´ê¸°' if self.dry_run else 'ìˆ˜ì •'}: {len(success_results)}ê°œ\n")
            f.write(f"ì‹¤íŒ¨: {len(failed_results)}ê°œ\n")
        
        self.log("\nğŸ“„ ê²°ê³¼ ì €ì¥:", force=True)
        self.log(f"   ë¡œê·¸: {log_file}", force=True)
        self.log(f"   JSON: {json_file}", force=True)
        self.log(f"   ìš”ì•½: {summary_file}", force=True)
    
    def print_summary(self, fix_data: Dict):
        """ìˆ˜ì • ê²°ê³¼ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤"""
        results = fix_data['results']
        
        success_count = len([r for r in results if r['status'] in ['success', 'dry_run']])
        failed_count = len([r for r in results if r['status'] == 'failed'])
        
        self.log("\n" + "="*70, force=True)
        self.log("âœ… ì‘ì—… ì™„ë£Œ", force=True)
        self.log("="*70, force=True)
        
        self.log(f"\nğŸ“Š í†µê³„:", force=True)
        self.log(f"   ì „ì²´: {len(results)}ê°œ", force=True)
        self.log(f"   {'ë¯¸ë¦¬ë³´ê¸°' if self.dry_run else 'ìˆ˜ì •'}: {success_count}ê°œ", force=True)
        self.log(f"   ì‹¤íŒ¨: {failed_count}ê°œ", force=True)
        
        self.log(f"\nğŸ“‹ ìˆ˜ì • ë‚´ì—­:", force=True)
        self.log(f"   í•„ë“œ: {fix_data['field_name']}", force=True)
        self.log(f"   ëŒ€ìƒ ê°’: {', '.join(fix_data['target_values'])}", force=True)
        self.log(f"   ë³€ê²½ ê°’: {fix_data['new_value']}", force=True)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="JSON í•„ë“œ ê°’ ìˆ˜ì • ë„êµ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--path',
        required=True,
        help='JSON íŒŒì¼ì´ ìˆëŠ” ê¸°ë³¸ ê²½ë¡œ'
    )
    parser.add_argument(
        '--folders',
        nargs='+',
        help='ìˆ˜ì •í•  íŠ¹ì • í´ë”ëª… (ìƒëµ ì‹œ ì „ì²´)'
    )
    parser.add_argument(
        '--field',
        required=True,
        help='ìˆ˜ì •í•  í•„ë“œëª…'
    )
    parser.add_argument(
        '--find',
        nargs='+',
        required=True,
        help='ì°¾ì„ ê°’ë“¤ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)'
    )
    parser.add_argument(
        '--replace',
        required=True,
        help='ë³€ê²½í•  ê°’'
    )
    parser.add_argument(
        '--output-dir',
        default='fix_results',
        help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: fix_results)'
    )
    parser.add_argument(
        '--recursive',
        action='store_true',
        help='í•˜ìœ„ í´ë”ê¹Œì§€ ì¬ê·€ íƒìƒ‰'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='ì‹¤ì œ ìˆ˜ì • ì—†ì´ ë¯¸ë¦¬ë³´ê¸°ë§Œ'
    )
    parser.add_argument(
        '--no-backup',
        action='store_true',
        help='ë°±ì—… íŒŒì¼ ìƒì„± ì•ˆí•¨'
    )
    parser.add_argument(
        '--quiet',
        action='store_true',
        help='ìµœì†Œí•œì˜ ì¶œë ¥ë§Œ í‘œì‹œ'
    )
    
    args = parser.parse_args()
    
    try:
        # ìˆ˜ì •ê¸° ìƒì„±
        fixer = JSONFieldFixer(
            base_path=args.path,
            output_dir=args.output_dir,
            backup=not args.no_backup,
            dry_run=args.dry_run,
            quiet=args.quiet
        )
        
        # ìˆ˜ì • ì‹¤í–‰
        fix_data = fixer.fix_folders(
            folder_names=args.folders,
            field_name=args.field,
            target_values=args.find,
            new_value=args.replace,
            recursive=args.recursive
        )
        
        if fix_data and fix_data['results']:
            # ê²°ê³¼ ì €ì¥
            fixer.save_results(fix_data)
            
            # ìš”ì•½ ì¶œë ¥
            fixer.print_summary(fix_data)
    
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
