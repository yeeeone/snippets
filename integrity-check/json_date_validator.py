"""
JSON Date Field Validator
==========================

JSON íŒŒì¼ì˜ ë‚ ì§œ í•„ë“œë¥¼ ê²€ì¦í•˜ê³  ì´ìƒê°’ì„ ì°¾ì•„ë‚´ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.

ì‚¬ìš©ë²• (Usage)
-------------

1. ê¸°ë³¸ ì‚¬ìš© (ë‹¨ì¼ í•„ë“œ ê²€ì¦)
   $ python json_date_validator.py --path ./data/uploads --field program_broadcasted_at

2. ì—¬ëŸ¬ í´ë” ê²€ì¦
   $ python json_date_validator.py --path ./data/uploads \
       --folders upload_20251224_001 upload_20251225_001 \
       --field program_broadcasted_at

3. ì—¬ëŸ¬ í•„ë“œ ë™ì‹œ ê²€ì¦
   $ python json_date_validator.py --path ./data/uploads \
       --field program_broadcasted_at created_at updated_at

4. ë‚ ì§œ í˜•ì‹ ì§€ì •
   $ python json_date_validator.py --path ./data \
       --field date_field \
       --date-formats "%Y%m%d" "%Y-%m-%d"

5. ì¬ê·€ ê²€ìƒ‰
   $ python json_date_validator.py --path ./data --field date --recursive

ê¸°ëŠ¥ (Features)
---------------
âœ“ ë‚ ì§œ í˜•ì‹ ê²€ì¦ (YYYYMMDD, YYYY-MM-DD ë“±)
âœ“ ì—¬ëŸ¬ í•„ë“œ ë™ì‹œ ê²€ì¦
âœ“ ëˆ„ë½/ì´ìƒê°’/ì˜¤ë¥˜ íŒŒì¼ ë¶„ë¥˜
âœ“ ìƒì„¸ ë¦¬í¬íŠ¸ ìë™ ìƒì„±
âœ“ ì¬ê·€ì  í´ë” íƒìƒ‰ ì§€ì›

ë‚ ì§œ í˜•ì‹ (Date Formats)
------------------------
ê¸°ë³¸ ì§€ì› í˜•ì‹:
  - YYYYMMDD (ì˜ˆ: 20250115)
  - YYYY-MM-DD (ì˜ˆ: 2025-01-15)

ì»¤ìŠ¤í…€ í˜•ì‹ ì§€ì •:
  --date-formats "%Y/%m/%d" "%d-%m-%Y"

ì¶œë ¥ (Output)
-------------
validation_results/
â”œâ”€â”€ invalid_dates_{timestamp}.txt    # ì´ìƒê°’ íŒŒì¼ ëª©ë¡
â”œâ”€â”€ invalid_dates_{timestamp}.json   # JSON í˜•ì‹ ê²°ê³¼
â””â”€â”€ summary_{timestamp}.txt          # ìš”ì•½ í†µê³„

ë””ë ‰í† ë¦¬ êµ¬ì¡° (Directory Structure)
-----------------------------------
project/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ uploads/
â”‚       â”œâ”€â”€ upload_20251224_001/
â”‚       â”‚   â”œâ”€â”€ file1.json
â”‚       â”‚   â””â”€â”€ file2.json
â”‚       â””â”€â”€ upload_20251225_001/
â”œâ”€â”€ validation_results/  # ìë™ ìƒì„±
â””â”€â”€ json_date_validator.py

ì˜µì…˜ (Options)
--------------
  --path PATH              JSON íŒŒì¼ì´ ìˆëŠ” ê¸°ë³¸ ê²½ë¡œ (í•„ìˆ˜)
  --folders NAMES          ê²€ì¦í•  íŠ¹ì • í´ë”ëª… (ì„ íƒ)
  --field FIELDS           ê²€ì¦í•  ë‚ ì§œ í•„ë“œëª… (í•„ìˆ˜, ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)
  --date-formats FORMATS   ë‚ ì§œ í˜•ì‹ (ê¸°ë³¸: %Y%m%d, %Y-%m-%d)
  --year-range MIN MAX     ìœ íš¨í•œ ì—°ë„ ë²”ìœ„ (ê¸°ë³¸: 1900-2100)
  --output-dir DIR         ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: validation_results)
  --recursive              í•˜ìœ„ í´ë”ê¹Œì§€ ì¬ê·€ ê²€ìƒ‰
  --quiet                  ìµœì†Œí•œì˜ ì¶œë ¥ë§Œ í‘œì‹œ
  -h, --help               ë„ì›€ë§ ì¶œë ¥

ì˜ˆì œ (Examples)
---------------

# 1. ë°©ì†¡ì¼ì í•„ë“œ ê²€ì¦
$ python json_date_validator.py \
    --path ./uploads \
    --field program_broadcasted_at

# 2. ì—¬ëŸ¬ ë‚ ì§œ í•„ë“œ ê²€ì¦
$ python json_date_validator.py \
    --path ./data \
    --field created_at updated_at published_at

# 3. íŠ¹ì • í´ë”ë§Œ ê²€ì¦
$ python json_date_validator.py \
    --path ./uploads \
    --folders upload_20251224_001 upload_20251225_001 \
    --field program_broadcasted_at

# 4. ì—°ë„ ë²”ìœ„ ì œí•œ
$ python json_date_validator.py \
    --path ./data \
    --field date \
    --year-range 2020 2025
"""

import os
import json
import argparse
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from collections import defaultdict


class JSONDateValidator:
    """JSON íŒŒì¼ì˜ ë‚ ì§œ í•„ë“œë¥¼ ê²€ì¦í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        base_path: str,
        output_dir: str = "validation_results",
        date_formats: Optional[List[str]] = None,
        year_range: Tuple[int, int] = (1900, 2100),
        quiet: bool = False
    ):
        """
        Args:
            base_path: JSON íŒŒì¼ì´ ìˆëŠ” ê¸°ë³¸ ê²½ë¡œ
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
            date_formats: ê²€ì¦í•  ë‚ ì§œ í˜•ì‹ ë¦¬ìŠ¤íŠ¸
            year_range: ìœ íš¨í•œ ì—°ë„ ë²”ìœ„ (min, max)
            quiet: Trueë©´ ìµœì†Œí•œì˜ ì¶œë ¥ë§Œ
        """
        self.base_path = Path(base_path)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True, parents=True)
        
        # ê¸°ë³¸ ë‚ ì§œ í˜•ì‹
        self.date_formats = date_formats or ["%Y%m%d", "%Y-%m-%d"]
        self.year_range = year_range
        self.quiet = quiet
        
        if not self.base_path.exists():
            raise ValueError(f"ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.base_path}")
    
    def log(self, message: str, force: bool = False):
        """ë¡œê·¸ ì¶œë ¥ (quiet ëª¨ë“œ ê³ ë ¤)"""
        if not self.quiet or force:
            print(message)
    
    def get_json_files(
        self,
        folder_path: Path,
        recursive: bool = False
    ) -> List[Path]:
        """
        í´ë”ì—ì„œ JSON íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤
        
        Args:
            folder_path: íƒìƒ‰í•  í´ë” ê²½ë¡œ
            recursive: Trueë©´ í•˜ìœ„ í´ë”ê¹Œì§€ ì¬ê·€ íƒìƒ‰
            
        Returns:
            JSON íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        if recursive:
            return list(folder_path.rglob("*.json"))
        else:
            return list(folder_path.glob("*.json"))
    
    def is_valid_date_format(self, date_str: str) -> Tuple[bool, Optional[str]]:
        """
        ë‚ ì§œ ë¬¸ìì—´ì´ ìœ íš¨í•œ í˜•ì‹ì¸ì§€ í™•ì¸
        
        Args:
            date_str: ê²€ì¦í•  ë‚ ì§œ ë¬¸ìì—´
            
        Returns:
            (ìœ íš¨ ì—¬ë¶€, ë§¤ì¹­ëœ í˜•ì‹)
        """
        if not date_str or not isinstance(date_str, str):
            return False, None
        
        for date_format in self.date_formats:
            try:
                parsed_date = datetime.strptime(date_str, date_format)
                year = parsed_date.year
                
                # ì—°ë„ ë²”ìœ„ í™•ì¸
                if self.year_range[0] <= year <= self.year_range[1]:
                    return True, date_format
            except (ValueError, TypeError):
                continue
        
        return False, None
    
    def check_json_file(
        self,
        json_path: Path,
        target_fields: List[str]
    ) -> Dict[str, Dict]:
        """
        JSON íŒŒì¼ì„ ì½ê³  ë‚ ì§œ í•„ë“œë¥¼ ê²€ì¦í•©ë‹ˆë‹¤
        
        Args:
            json_path: JSON íŒŒì¼ ê²½ë¡œ
            target_fields: ê²€ì¦í•  í•„ë“œëª… ë¦¬ìŠ¤íŠ¸
            
        Returns:
            í•„ë“œë³„ ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        results = {}
        
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            for field in target_fields:
                date_value = data.get(field, None)
                
                if date_value is None:
                    results[field] = {
                        'status': 'missing',
                        'file_id': json_path.stem,
                        'file_path': str(json_path),
                        'value': None,
                        'reason': f'{field} í•„ë“œ ì—†ìŒ'
                    }
                else:
                    is_valid, matched_format = self.is_valid_date_format(date_value)
                    
                    if not is_valid:
                        results[field] = {
                            'status': 'invalid',
                            'file_id': json_path.stem,
                            'file_path': str(json_path),
                            'value': date_value,
                            'reason': f'ì˜ëª»ëœ í˜•ì‹: {date_value}'
                        }
                    else:
                        results[field] = {
                            'status': 'valid',
                            'file_id': json_path.stem,
                            'file_path': str(json_path),
                            'value': date_value,
                            'format': matched_format,
                            'reason': 'OK'
                        }
        
        except json.JSONDecodeError as e:
            for field in target_fields:
                results[field] = {
                    'status': 'error',
                    'file_id': json_path.stem,
                    'file_path': str(json_path),
                    'value': None,
                    'reason': f'JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}'
                }
        
        except Exception as e:
            for field in target_fields:
                results[field] = {
                    'status': 'error',
                    'file_id': json_path.stem,
                    'file_path': str(json_path),
                    'value': None,
                    'reason': f'ì½ê¸° ì˜¤ë¥˜: {str(e)}'
                }
        
        return results
    
    def validate_folders(
        self,
        folder_names: Optional[List[str]] = None,
        target_fields: List[str] = None,
        recursive: bool = False
    ) -> Dict:
        """
        í´ë”ë“¤ì˜ JSON íŒŒì¼ì„ ê²€ì¦í•©ë‹ˆë‹¤
        
        Args:
            folder_names: ê²€ì¦í•  í´ë”ëª… ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ base_path ì „ì²´)
            target_fields: ê²€ì¦í•  í•„ë“œëª… ë¦¬ìŠ¤íŠ¸
            recursive: ì¬ê·€ íƒìƒ‰ ì—¬ë¶€
            
        Returns:
            ì „ì²´ ê²€ì¦ ê²°ê³¼
        """
        if not target_fields:
            raise ValueError("ê²€ì¦í•  í•„ë“œëª…ì„ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤ (--field)")
        
        self.log("="*70, force=True)
        self.log("ğŸ” JSON ë‚ ì§œ í•„ë“œ ê²€ì¦ ì‹œì‘", force=True)
        self.log("="*70, force=True)
        self.log(f"ğŸ“‚ ê¸°ë³¸ ê²½ë¡œ: {self.base_path}", force=True)
        self.log(f"ğŸ“‹ ê²€ì¦ í•„ë“œ: {', '.join(target_fields)}", force=True)
        self.log(f"ğŸ“… ë‚ ì§œ í˜•ì‹: {', '.join(self.date_formats)}", force=True)
        self.log("")
        
        # í´ë” ëª©ë¡ ê²°ì •
        if folder_names:
            folders = [self.base_path / folder for folder in folder_names]
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í´ë” í•„í„°ë§
            folders = [f for f in folders if f.exists() and f.is_dir()]
            if not folders:
                self.log("âŒ ì§€ì •í•œ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", force=True)
                return {}
        else:
            # base_path ìì²´ë¥¼ ê²€ì¦
            folders = [self.base_path]
        
        # í•„ë“œë³„ ê²°ê³¼ ì €ì¥
        all_results = {field: defaultdict(list) for field in target_fields}
        
        for folder in folders:
            folder_name = folder.name
            self.log(f"ğŸ“ [{folder_name}] ê²€ì‚¬ ì¤‘...")
            
            json_files = self.get_json_files(folder, recursive)
            self.log(f"   ì´ JSON íŒŒì¼: {len(json_files)}ê°œ")
            
            if not json_files:
                self.log(f"   âš ï¸ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\n")
                continue
            
            # í•„ë“œë³„ ì¹´ìš´í„°
            field_counters = {
                field: {'valid': 0, 'invalid': 0, 'missing': 0, 'error': 0}
                for field in target_fields
            }
            
            for idx, json_file in enumerate(json_files, 1):
                if idx % 1000 == 0 or idx == 1:
                    self.log(f"   [{idx}/{len(json_files)}] ì²˜ë¦¬ ì¤‘...")
                
                results = self.check_json_file(json_file, target_fields)
                
                for field, result in results.items():
                    status = result['status']
                    all_results[field][status].append(result)
                    field_counters[field][status] += 1
            
            # í´ë”ë³„ í†µê³„ ì¶œë ¥
            self.log(f"\n   âœ… ê²€ì‚¬ ì™„ë£Œ")
            for field in target_fields:
                counter = field_counters[field]
                self.log(f"   [{field}]")
                self.log(f"      ìœ íš¨: {counter['valid']}ê°œ")
                self.log(f"      ì´ìƒê°’: {counter['invalid']}ê°œ")
                self.log(f"      ëˆ„ë½: {counter['missing']}ê°œ")
                self.log(f"      ì˜¤ë¥˜: {counter['error']}ê°œ")
            self.log("")
        
        return all_results
    
    def save_results(
        self,
        results: Dict,
        target_fields: List[str]
    ):
        """
        ê²€ì¦ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤
        
        Args:
            results: ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            target_fields: ê²€ì¦í•œ í•„ë“œëª… ë¦¬ìŠ¤íŠ¸
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸
        report_file = self.output_dir / f"invalid_dates_{timestamp}.txt"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("="*70 + "\n")
            f.write("JSON ë‚ ì§œ í•„ë“œ ê²€ì¦ ë¦¬í¬íŠ¸\n")
            f.write("="*70 + "\n")
            f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ê²€ì¦ í•„ë“œ: {', '.join(target_fields)}\n")
            f.write("="*70 + "\n\n")
            
            for field in target_fields:
                field_results = results[field]
                
                f.write(f"\n{'='*70}\n")
                f.write(f"í•„ë“œ: {field}\n")
                f.write(f"{'='*70}\n\n")
                
                # ì´ìƒê°’
                if field_results['invalid']:
                    f.write(f"âŒ ì˜ëª»ëœ í˜•ì‹ ({len(field_results['invalid'])}ê°œ):\n")
                    f.write("-"*70 + "\n")
                    for result in sorted(field_results['invalid'], key=lambda x: x['file_id']):
                        f.write(f"{result['file_id']}: {result['value']}\n")
                    f.write("\n")
                
                # ëˆ„ë½
                if field_results['missing']:
                    f.write(f"âš ï¸ í•„ë“œ ëˆ„ë½ ({len(field_results['missing'])}ê°œ):\n")
                    f.write("-"*70 + "\n")
                    for result in sorted(field_results['missing'], key=lambda x: x['file_id']):
                        f.write(f"{result['file_id']}\n")
                    f.write("\n")
                
                # ì˜¤ë¥˜
                if field_results['error']:
                    f.write(f"âŒ ì½ê¸° ì˜¤ë¥˜ ({len(field_results['error'])}ê°œ):\n")
                    f.write("-"*70 + "\n")
                    for result in sorted(field_results['error'], key=lambda x: x['file_id']):
                        f.write(f"{result['file_id']}: {result['reason']}\n")
                    f.write("\n")
                
                # í†µê³„
                f.write("-"*70 + "\n")
                f.write(f"ìœ íš¨: {len(field_results['valid'])}ê°œ\n")
                f.write(f"ì´ìƒê°’: {len(field_results['invalid'])}ê°œ\n")
                f.write(f"ëˆ„ë½: {len(field_results['missing'])}ê°œ\n")
                f.write(f"ì˜¤ë¥˜: {len(field_results['error'])}ê°œ\n")
        
        # JSON ë¦¬í¬íŠ¸
        json_file = self.output_dir / f"invalid_dates_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        # ìš”ì•½ í†µê³„
        summary_file = self.output_dir / f"summary_{timestamp}.txt"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("="*70 + "\n")
            f.write("ê²€ì¦ ìš”ì•½\n")
            f.write("="*70 + "\n\n")
            
            for field in target_fields:
                field_results = results[field]
                total = sum(len(field_results[status]) for status in ['valid', 'invalid', 'missing', 'error'])
                
                f.write(f"[{field}]\n")
                f.write(f"  ì „ì²´: {total}ê°œ\n")
                f.write(f"  ìœ íš¨: {len(field_results['valid'])}ê°œ ({len(field_results['valid'])/total*100:.1f}%)\n")
                f.write(f"  ì´ìƒê°’: {len(field_results['invalid'])}ê°œ\n")
                f.write(f"  ëˆ„ë½: {len(field_results['missing'])}ê°œ\n")
                f.write(f"  ì˜¤ë¥˜: {len(field_results['error'])}ê°œ\n\n")
        
        self.log("\nğŸ“„ ê²°ê³¼ ì €ì¥:", force=True)
        self.log(f"   ë¦¬í¬íŠ¸: {report_file}", force=True)
        self.log(f"   JSON: {json_file}", force=True)
        self.log(f"   ìš”ì•½: {summary_file}", force=True)
    
    def print_summary(self, results: Dict, target_fields: List[str]):
        """ê²€ì¦ ê²°ê³¼ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤"""
        self.log("\n" + "="*70, force=True)
        self.log("âœ… ê²€ì¦ ì™„ë£Œ", force=True)
        self.log("="*70, force=True)
        
        for field in target_fields:
            field_results = results[field]
            total = sum(len(field_results[status]) for status in ['valid', 'invalid', 'missing', 'error'])
            
            self.log(f"\nğŸ“Š [{field}] í†µê³„:", force=True)
            self.log(f"   ì „ì²´: {total}ê°œ", force=True)
            self.log(f"   ìœ íš¨: {len(field_results['valid'])}ê°œ", force=True)
            self.log(f"   ì´ìƒê°’: {len(field_results['invalid'])}ê°œ", force=True)
            self.log(f"   ëˆ„ë½: {len(field_results['missing'])}ê°œ", force=True)
            self.log(f"   ì˜¤ë¥˜: {len(field_results['error'])}ê°œ", force=True)
            
            # ì´ìƒê°’ ìƒ˜í”Œ ì¶œë ¥
            if field_results['invalid']:
                self.log(f"\n   âš ï¸ ì´ìƒê°’ ìƒ˜í”Œ:", force=True)
                for result in field_results['invalid'][:5]:
                    self.log(f"      {result['file_id']}: {result['value']}", force=True)
                if len(field_results['invalid']) > 5:
                    self.log(f"      ... ì™¸ {len(field_results['invalid']) - 5}ê°œ", force=True)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="JSON ë‚ ì§œ í•„ë“œ ê²€ì¦ ë„êµ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--path',
        required=True,
        help='JSON íŒŒì¼ì´ ìˆëŠ” ê¸°ë³¸ ê²½ë¡œ'
    )
    parser.add_argument(
        '--folders',
        nargs='+',
        help='ê²€ì¦í•  íŠ¹ì • í´ë”ëª… (ìƒëµ ì‹œ ì „ì²´ ê²€ì¦)'
    )
    parser.add_argument(
        '--field',
        nargs='+',
        required=True,
        help='ê²€ì¦í•  ë‚ ì§œ í•„ë“œëª… (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)'
    )
    parser.add_argument(
        '--date-formats',
        nargs='+',
        help='ë‚ ì§œ í˜•ì‹ (ì˜ˆ: %%Y%%m%%d %%Y-%%m-%%d)'
    )
    parser.add_argument(
        '--year-range',
        nargs=2,
        type=int,
        default=[1900, 2100],
        metavar=('MIN', 'MAX'),
        help='ìœ íš¨í•œ ì—°ë„ ë²”ìœ„ (ê¸°ë³¸: 1900 2100)'
    )
    parser.add_argument(
        '--output-dir',
        default='validation_results',
        help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: validation_results)'
    )
    parser.add_argument(
        '--recursive',
        action='store_true',
        help='í•˜ìœ„ í´ë”ê¹Œì§€ ì¬ê·€ íƒìƒ‰'
    )
    parser.add_argument(
        '--quiet',
        action='store_true',
        help='ìµœì†Œí•œì˜ ì¶œë ¥ë§Œ í‘œì‹œ'
    )
    
    args = parser.parse_args()
    
    try:
        # ê²€ì¦ê¸° ìƒì„±
        validator = JSONDateValidator(
            base_path=args.path,
            output_dir=args.output_dir,
            date_formats=args.date_formats,
            year_range=tuple(args.year_range),
            quiet=args.quiet
        )
        
        # ê²€ì¦ ì‹¤í–‰
        results = validator.validate_folders(
            folder_names=args.folders,
            target_fields=args.field,
            recursive=args.recursive
        )
        
        if results:
            # ê²°ê³¼ ì €ì¥
            validator.save_results(results, args.field)
            
            # ìš”ì•½ ì¶œë ¥
            validator.print_summary(results, args.field)
    
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
